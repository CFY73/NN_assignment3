{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.nn import GCNConv, BatchNorm\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "def load_data(filepath):\n",
    "    \"\"\"\n",
    "    Load the data and split it into training and testing sets with a 3:7 ratio.\n",
    "\n",
    "    Parameters:\n",
    "    filepath (str): Path to the data file\n",
    "\n",
    "    Returns:\n",
    "    X_train, X_test, y_train, y_test: Features and target for training and testing sets\n",
    "    \"\"\"\n",
    "\n",
    "    data = pd.read_csv(filepath)\n",
    "    \n",
    "    X = data.drop(columns=['Rings'])  \n",
    "    y = data['Rings']\n",
    "    \n",
    "    \n",
    "    return X,y\n",
    "\n",
    "def create_graph_data(X, y, K=5):\n",
    "    \"\"\"\n",
    "    Preprocess features and labels to create a PyTorch Geometric Data object.\n",
    "\n",
    "    Parameters:\n",
    "    - X: Feature DataFrame\n",
    "    - y: Target Series\n",
    "    - K: Number of neighbors for KNN adjacency matrix\n",
    "\n",
    "    Returns:\n",
    "    - graph_data: PyTorch Geometric Data object with x, edge_index, and y attributes\n",
    "    - input_features: Number of input features for the model\n",
    "    \"\"\"\n",
    "    # Standardize features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    # Convert y to a tensor\n",
    "    y_adjusted=y-1\n",
    "    y_tensor = torch.tensor(y_adjusted.values, dtype=torch.long)  # Use long for classification\n",
    "\n",
    "    # Create adjacency matrix using KNN\n",
    "    adjacency_matrix = kneighbors_graph(X_scaled, K, mode='connectivity', include_self=False).toarray()\n",
    "\n",
    "    # Convert adjacency matrix to edge index format\n",
    "    edge_index = []\n",
    "    for i in range(adjacency_matrix.shape[0]):\n",
    "        for j in range(adjacency_matrix.shape[1]):\n",
    "            if adjacency_matrix[i, j] == 1:\n",
    "                edge_index.append([i, j])\n",
    "    edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "\n",
    "    # Convert X to a tensor for the features\n",
    "    x_tensor = torch.tensor(X_scaled, dtype=torch.float)\n",
    "    \n",
    "    # Create graph data object\n",
    "    graph_data = Data(x=x_tensor, edge_index=edge_index, y=y_tensor)\n",
    "    input_features = X_scaled.shape[1]\n",
    "    \n",
    "    return graph_data, input_features\n",
    "\n",
    "\n",
    "\n",
    "# 定义 GCN 模型\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, input_features, hidden_dim, dropout_rate, num_classes=4):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(input_features, hidden_dim)\n",
    "        self.bn1 = BatchNorm(hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, hidden_dim)\n",
    "        self.bn2 = BatchNorm(hidden_dim)\n",
    "        self.conv3 = GCNConv(hidden_dim, num_classes)\n",
    "        self.dropout_rate = dropout_rate\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=self.dropout_rate, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=self.dropout_rate, training=self.training)\n",
    "        x = self.conv3(x, edge_index)\n",
    "        return x\n",
    "\n",
    "# 超参数网格搜索函数\n",
    "def grid_search_gcn(graph_data, input_features, num_classes=4, epochs=100):\n",
    "    # 定义超参数搜索空间\n",
    "    param_grid = {\n",
    "        'hidden_dim': [32, 64, 128],\n",
    "        'dropout_rate': [0.3, 0.5, 0.7],\n",
    "        'learning_rate': [0.01, 0.005, 0.001],\n",
    "        'weight_decay': [5e-4, 1e-4, 1e-5]\n",
    "    }\n",
    "\n",
    "    # 定义用于存储最佳结果的变量\n",
    "    best_accuracy = 0\n",
    "    best_params = None\n",
    "\n",
    "    # 遍历每个超参数组合\n",
    "    for hidden_dim in param_grid['hidden_dim']:\n",
    "        for dropout_rate in param_grid['dropout_rate']:\n",
    "            for learning_rate in param_grid['learning_rate']:\n",
    "                for weight_decay in param_grid['weight_decay']:\n",
    "                    print(f\"\\nTraining with hidden_dim={hidden_dim}, dropout_rate={dropout_rate}, \"\n",
    "                          f\"learning_rate={learning_rate}, weight_decay={weight_decay}\")\n",
    "                    \n",
    "                    # 初始化模型和优化器\n",
    "                    model = GCN(input_features, hidden_dim, dropout_rate, num_classes)\n",
    "                    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "                    criterion = torch.nn.CrossEntropyLoss()\n",
    "                    \n",
    "                    # 训练模型\n",
    "                    for epoch in range(epochs):\n",
    "                        model.train()\n",
    "                        optimizer.zero_grad()\n",
    "                        out = model(graph_data)\n",
    "                        loss = criterion(out, graph_data.y)\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                    # 评估模型\n",
    "                    model.eval()\n",
    "                    with torch.no_grad():\n",
    "                        logits = model(graph_data)\n",
    "                        predictions = logits.argmax(dim=1)\n",
    "                        accuracy = accuracy_score(graph_data.y.cpu(), predictions.cpu())\n",
    "\n",
    "                        print(f\"Accuracy with current parameters: {accuracy * 100:.2f}%\")\n",
    "                        \n",
    "                        # 检查当前超参数组合是否是最佳\n",
    "                        if accuracy > best_accuracy:\n",
    "                            best_accuracy = accuracy\n",
    "                            best_params = {\n",
    "                                'hidden_dim': hidden_dim,\n",
    "                                'dropout_rate': dropout_rate,\n",
    "                                'learning_rate': learning_rate,\n",
    "                                'weight_decay': weight_decay\n",
    "                            }\n",
    "\n",
    "    # 输出最佳超参数组合和对应的准确率\n",
    "    print(\"\\nBest Parameters:\")\n",
    "    print(f\"Hidden Dimension: {best_params['hidden_dim']}\")\n",
    "    print(f\"Dropout Rate: {best_params['dropout_rate']}\")\n",
    "    print(f\"Learning Rate: {best_params['learning_rate']}\")\n",
    "    print(f\"Weight Decay: {best_params['weight_decay']}\")\n",
    "    print(f\"Best Accuracy: {best_accuracy * 100:.2f}%\")\n",
    "\n",
    "# 假设已生成 graph_data 和 input_features\n",
    "# grid_search_gcn(graph_data, input_features)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
